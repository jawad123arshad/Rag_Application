# import streamlit as st
# import pandas as pd
# import plotly.graph_objects as go
# from plotly.subplots import make_subplots
# from datetime import datetime
# import json
# import sys
# import os

# # Add current directory to path
# sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# from rag_core import RAGLearningAssistant
# from config import config

# # Page configuration
# st.set_page_config(
#     page_title="LearnAI RAG Assistant",
#     page_icon="ü§ñ",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# # Custom CSS
# st.markdown("""
# <style>
#     .main-header {
#         font-size: 2.5rem;
#         color: #1E3A8A;
#         margin-bottom: 1rem;
#     }
#     .sub-header {
#         font-size: 1.5rem;
#         color: #3B82F6;
#         margin-bottom: 1rem;
#     }
#     .card {
#         background-color: #F8FAFC;
#         border-radius: 10px;
#         padding: 20px;
#         margin-bottom: 20px;
#         border-left: 5px solid #3B82F6;
#     }
#     .success-box {
#         background-color: #D1FAE5;
#         border-radius: 10px;
#         padding: 15px;
#         margin: 10px 0;
#     }
#     .info-box {
#         background-color: #DBEAFE;
#         border-radius: 10px;
#         padding: 15px;
#         margin: 10px 0;
#     }
#     .code-header {
#         background-color: #1E293B;
#         color: white;
#         padding: 10px;
#         border-radius: 5px 5px 0 0;
#         font-family: 'Courier New', monospace;
#     }
#     .stButton button {
#         width: 100%;
#         background-color: #3B82F6;
#         color: white;
#     }
# </style>
# """, unsafe_allow_html=True)

# class LearnAIApp:
#     def __init__(self):
#         self.assistant = None
#         self.user_id = "default"
        
#     def initialize_assistant(self):
#         """Initialize the RAG assistant"""
#         if self.assistant is None:
#             with st.spinner("Loading AI Learning Assistant..."):
#                 self.assistant = RAGLearningAssistant(config)
    
#     def run(self):
#         """Main application runner"""
#         self.initialize_assistant()
        
#         # Sidebar
#         self.render_sidebar()
        
#         # Main content
#         self.render_main_content()
    
#     def render_sidebar(self):
#         """Render sidebar with navigation and user info"""
#         with st.sidebar:
#             st.image("https://cdn-icons-png.flaticon.com/512/2103/2103655.png", width=100)
#             st.markdown("<h2 style='text-align: center;'>LearnAI Assistant</h2>", unsafe_allow_html=True)
            
#             # User session
#             st.markdown("### üë§ Learning Session")
#             user_name = st.text_input("Your Name", value="AI Learner")
#             self.user_id = user_name.lower().replace(" ", "_")
            
#             # Learning mode
#             st.markdown("### üéØ Learning Mode")
#             mode = st.radio(
#                 "Select Mode:",
#                 ["Interactive Learning", "Structured Lessons", "Project Mode", "Interview Prep"]
#             )
            
#             # Difficulty level
#             st.markdown("### üìä Difficulty Level")
#             difficulty = st.select_slider(
#                 "Adjust difficulty:",
#                 options=["Beginner", "Intermediate", "Advanced", "Expert"],
#                 value="Intermediate"
#             )
            
#             # Quick actions
#             st.markdown("### ‚ö° Quick Actions")
#             col1, col2 = st.columns(2)
#             with col1:
#                 if st.button("üìö Review Basics"):
#                     st.session_state.quick_action = "review_basics"
#             with col2:
#                 if st.button("üí° Get Project Idea"):
#                     st.session_state.quick_action = "project_idea"
            
#             # Learning progress
#             st.markdown("### üìà Your Progress")
#             if self.assistant:
#                 progress = self.assistant.get_learning_progress(self.user_id)
#                 st.progress(int(progress["progress"]))
#                 st.caption(f"Level: {progress['level']}")
#                 st.caption(f"Topics covered: {len(progress['topics_covered'])}")
            
#             # System info
#             st.markdown("---")
#             st.markdown("### üîß System Info")
#             st.caption(f"Model: {config.model.LLM_MODEL}")
#             st.caption(f"Embeddings: {config.model.EMBEDDING_MODEL}")
#             st.caption("Status: ‚úÖ Active")
    
#     def render_main_content(self):
#         """Render main content area"""
#         # Header
#         st.markdown("<h1 class='main-header'>ü§ñ LearnAI RAG Assistant</h1>", unsafe_allow_html=True)
#         st.markdown("""
#         <div class='info-box'>
#         <strong>Your personal AI tutor:</strong> Learn Machine Learning, Deep Learning, and AI concepts through interactive Q&A, 
#         code examples, and personalized learning paths. Built with advanced RAG technology.
#         </div>
#         """, unsafe_allow_html=True)
        
#         # Tab navigation
#         tab1, tab2, tab3, tab4, tab5 = st.tabs([
#             "üí¨ Chat & Learn", 
#             "üìö Lesson Plans", 
#             "üìä Analytics", 
#             "üõ†Ô∏è System Demo", 
#             "üìÑ Portfolio"
#         ])
        
#         with tab1:
#             self.render_chat_interface()
        
#         with tab2:
#             self.render_lesson_plans()
        
#         with tab3:
#             self.render_analytics()
        
#         with tab4:
#             self.render_system_demo()
        
#         with tab5:
#             self.render_portfolio()
    
#     def render_chat_interface(self):
#         """Render chat interface"""
#         st.markdown("<h2 class='sub-header'>üí¨ Interactive Learning Chat</h2>", unsafe_allow_html=True)
        
#         # Initialize chat history
#         if "messages" not in st.session_state:
#             st.session_state.messages = []
        
#         # Display chat messages
#         for message in st.session_state.messages:
#             with st.chat_message(message["role"]):
#                 st.markdown(message["content"])
        
#         # Chat input
#         if prompt := st.chat_input("Ask about any AI/ML concept..."):
#             # Add user message
#             st.session_state.messages.append({"role": "user", "content": prompt})
#             with st.chat_message("user"):
#                 st.markdown(prompt)
            
#             # Get response
#             with st.chat_message("assistant"):
#                 with st.spinner("Thinking..."):
#                     response = self.assistant.query(prompt, self.user_id)
                    
#                     # Display answer
#                     st.markdown(response["answer"])
                    
#                     # Display sources
#                     with st.expander("üìö View Sources & Details"):
#                         self.display_response_details(response)
            
#             # Add assistant response to history
#             st.session_state.messages.append({
#                 "role": "assistant", 
#                 "content": response["answer"]
#             })
        
#         # Quick query buttons
#         st.markdown("### üöÄ Quick Queries")
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             if st.button("What is RAG?"):
#                 st.session_state.messages.append({"role": "user", "content": "What is Retrieval Augmented Generation?"})
#         with col2:
#             if st.button("Explain transformers"):
#                 st.session_state.messages.append({"role": "user", "content": "Explain transformer architecture in simple terms"})
#         with col3:
#             if st.button("Show ML code example"):
#                 st.session_state.messages.append({"role": "user", "content": "Show me a complete machine learning code example with explanations"})
    
#     def display_response_details(self, response):
#         """Display detailed response information"""
#         # Sources
#         st.markdown("#### üìñ Sources Used:")
#         for i, source in enumerate(response["sources"]):
#             st.markdown(f"""
#             **{i+1}. {source['title']}**
#             - Source: `{source['source']}`
#             - Difficulty: {source['difficulty']}
#             - Relevance: {source['relevance_score']:.2%}
#             """)
        
#         # Metadata
#         st.markdown("#### üìä Performance Metrics:")
#         metadata = response["metadata"]
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             st.metric("Response Time", f"{metadata['response_time']:.2f}s")
#         with col2:
#             st.metric("Sources", metadata["sources_count"])
#         with col3:
#             st.metric("Tokens", metadata["tokens_used"])
        
#         # Learning tips
#         st.markdown("#### üí° Learning Tips:")
#         for tip in response["learning_tips"]:
#             st.markdown(f"- {tip}")
        
#         # Next steps
#         st.markdown("#### üéØ Next Steps:")
#         for step in response["next_steps"]:
#             st.markdown(f"- **{step['action'].title()}**: {step.get('topic', step.get('exercise', step.get('aspect', '')))} - {step['reason']}")
    
#     def render_lesson_plans(self):
#         """Render lesson plans interface"""
#         st.markdown("<h2 class='sub-header'>üìö Structured Learning Paths</h2>", unsafe_allow_html=True)
        
#         # Topic selection
#         col1, col2 = st.columns(2)
#         with col1:
#             topic = st.selectbox(
#                 "Choose a topic:",
#                 ["Machine Learning Basics", "Deep Learning", "Natural Language Processing", 
#                  "Computer Vision", "Reinforcement Learning", "RAG Systems"]
#             )
#         with col2:
#             level = st.selectbox(
#                 "Select level:",
#                 ["Beginner", "Intermediate", "Advanced"]
#             )
        
#         # Generate lesson plan
#         if st.button("Generate Lesson Plan", type="primary"):
#             with st.spinner("Creating personalized lesson plan..."):
#                 lesson_plan = self.assistant.generate_lesson_plan(topic, level)
                
#                 if "error" in lesson_plan:
#                     st.error(lesson_plan["error"])
#                 else:
#                     self.display_lesson_plan(lesson_plan)
        
#         # Pre-defined learning paths
#         st.markdown("### üõ£Ô∏è Pre-defined Learning Paths")
        
#         paths = {
#             "ML Engineer Track": [
#                 "Python & Data Science Basics",
#                 "ML Algorithms & Statistics",
#                 "Model Deployment & MLOps",
#                 "Advanced ML Systems"
#             ],
#             "NLP Specialist": [
#                 "Text Processing Basics",
#                 "Word Embeddings & RNNs",
#                 "Transformers & BERT",
#                 "Advanced NLP Applications"
#             ],
#             "AI Researcher": [
#                 "Advanced Mathematics",
#                 "Research Methodology",
#                 "Latest Papers & Trends",
#                 "Contribution Strategies"
#             ]
#         }
        
#         selected_path = st.selectbox("Choose a career path:", list(paths.keys()))
        
#         if selected_path:
#             st.markdown(f"### üìã {selected_path}")
#             for i, step in enumerate(paths[selected_path], 1):
#                 st.markdown(f"{i}. **{step}**")
#                 if st.button(f"Start Step {i}", key=f"path_{i}"):
#                     st.info(f"Starting: {step}")
    
#     def display_lesson_plan(self, lesson_plan):
#         """Display generated lesson plan"""
#         st.markdown(f"## üéì Lesson Plan: {lesson_plan['topic']}")
#         st.markdown(f"**Level:** {lesson_plan['level']} | **Estimated Time:** {lesson_plan['estimated_time']}")
        
#         # Modules
#         for i, module in enumerate(lesson_plan["modules"]):
#             with st.expander(f"Module {i+1}: {module['title']} ({module['duration']})"):
#                 st.markdown("**Objectives:**")
#                 for obj in module["objectives"]:
#                     st.markdown(f"- {obj}")
                
#                 st.markdown("**Content:**")
#                 st.markdown(module["content"])
        
#         # Assessment
#         st.markdown("### üìù Assessment")
        
#         # Quiz
#         if "quiz_questions" in lesson_plan["assessment"]:
#             st.markdown("#### Quiz Questions")
#             for i, question in enumerate(lesson_plan["assessment"]["quiz_questions"]):
#                 with st.expander(f"Question {i+1}: {question['question']}"):
#                     for j, option in enumerate(question["options"]):
#                         st.markdown(f"{j+1}. {option}")
#                     st.success(f"**Answer:** {question['correct_answer'] + 1}")
#                     st.info(f"**Explanation:** {question['explanation']}")
        
#         # Coding exercises
#         if "coding_exercises" in lesson_plan["assessment"]:
#             st.markdown("#### üíª Coding Exercises")
#             for exercise in lesson_plan["assessment"]["coding_exercises"]:
#                 st.code(f"# Exercise: {exercise}\n# Your code here...", language="python")
        
#         # Project ideas
#         if "project_ideas" in lesson_plan["assessment"]:
#             st.markdown("#### üöÄ Project Ideas")
#             for idea in lesson_plan["assessment"]["project_ideas"]:
#                 st.markdown(f"- {idea}")
        
#         # Resources
#         st.markdown("### üìö Recommended Resources")
#         df = pd.DataFrame(lesson_plan["resources"])
#         if not df.empty:
#             st.dataframe(df)
    
#     def render_analytics(self):
#         """Render analytics dashboard"""
#         st.markdown("<h2 class='sub-header'>üìä Learning Analytics Dashboard</h2>", unsafe_allow_html=True)
        
#         if not self.assistant:
#             st.warning("Please initialize the assistant first")
#             return
        
#         # Get user progress
#         progress = self.assistant.get_learning_progress(self.user_id)
        
#         # Metrics
#         col1, col2, col3, col4 = st.columns(4)
#         with col1:
#             st.metric("Learning Level", progress["level"])
#         with col2:
#             st.metric("Progress", f"{progress['progress']:.1f}%")
#         with col3:
#             st.metric("Topics Covered", len(progress["topics_covered"]))
#         with col4:
#             st.metric("Total Queries", progress["total_queries"])
        
#         # Progress visualization
#         fig = make_subplots(
#             rows=2, cols=2,
#             subplot_titles=("Progress Over Time", "Topic Distribution", 
#                           "Query Analysis", "Learning Velocity"),
#             specs=[[{"type": "scatter"}, {"type": "pie"}],
#                    [{"type": "bar"}, {"type": "indicator"}]]
#         )
        
#         # Progress chart (simulated data)
#         days = list(range(1, 31))
#         progress_data = [min(100, i * 3.5) for i in days]
#         fig.add_trace(
#             go.Scatter(x=days, y=progress_data, mode='lines+markers', name='Progress'),
#             row=1, col=1
#         )
        
#         # Topic distribution
#         if progress["topics_covered"]:
#             topics = progress["topics_covered"]
#             topic_counts = {topic: topics.count(topic) for topic in set(topics)}
#             fig.add_trace(
#                 go.Pie(labels=list(topic_counts.keys()), values=list(topic_counts.values())),
#                 row=1, col=2
#             )
        
#         # Query analysis (simulated)
#         query_types = ['Definition', 'Implementation', 'Comparison', 'Project']
#         query_counts = [25, 40, 15, 20]
#         fig.add_trace(
#             go.Bar(x=query_types, y=query_counts, name='Query Types'),
#             row=2, col=1
#         )
        
#         # Learning velocity indicator
#         fig.add_trace(
#             go.Indicator(
#                 mode="gauge+number",
#                 value=75,
#                 title={"text": "Learning Velocity"},
#                 domain={'row': 1, 'col': 1},
#                 gauge={'axis': {'range': [0, 100]}}
#             ),
#             row=2, col=2
#         )
        
#         fig.update_layout(height=600, showlegend=False)
#         st.plotly_chart(fig, use_container_width=True)
        
#         # Detailed analysis
#         st.markdown("### üîç Detailed Analysis")
        
#         # Topic mastery
#         st.markdown("#### Topic Mastery")
#         mastery_data = {
#             "Machine Learning": 85,
#             "Deep Learning": 70,
#             "Natural Language Processing": 60,
#             "Computer Vision": 45,
#             "Reinforcement Learning": 30
#         }
        
#         for topic, score in mastery_data.items():
#             st.markdown(f"**{topic}**")
#             st.progress(score / 100)
        
#         # Recommendations
#         st.markdown("### üéØ Personalized Recommendations")
#         recommendations = [
#             "Focus on Reinforcement Learning to broaden your skills",
#             "Try building a complete project end-to-end",
#             "Review model evaluation metrics",
#             "Practice explaining concepts to others"
#         ]
        
#         for rec in recommendations:
#             st.markdown(f"- {rec}")
    
#     def render_system_demo(self):
#         """Render system demonstration"""
#         st.markdown("<h2 class='sub-header'>üõ†Ô∏è System Architecture & Demo</h2>", unsafe_allow_html=True)
        
#         st.markdown("""
#         <div class='card'>
#         <h3>üìã System Overview</h3>
#         <p>This RAG system demonstrates advanced ML techniques for educational AI:</p>
#         </div>
#         """, unsafe_allow_html=True)
        
#         # Architecture diagram
#         st.markdown("### üèóÔ∏è System Architecture")
#         st.image("https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBBW1VzZXIgUXVlcnldIC0tPiBCW1F1ZXJ5IEFuYWx5c2lzXVxuICAgIEIgLS0-IENbU2VtYW50aWMgUmV0cmlldmFsXVxuICAgIEIgLS0-IEQ[KEY3]IiwiZWRpdG9ycyI6W3siY2F0ZWdvcnkiOiIyIn1dfQ==")
        
#         # Components showcase
#         st.markdown("### ‚öôÔ∏è Key Components")
        
#         components = [
#             {
#                 "name": "Hybrid Retriever",
#                 "description": "Combines semantic search (embeddings) with keyword search (BM25)",
#                 "features": ["FAISS index for fast similarity", "Cross-encoder reranking", "Difficulty-based filtering"]
#             },
#             {
#                 "name": "Knowledge Processor",
#                 "description": "ML-based document processing pipeline",
#                 "features": ["Automatic topic extraction", "Difficulty assessment", "Smart chunking"]
#             },
#             {
#                 "name": "Adaptive Learning Engine",
#                 "description": "Personalizes responses based on user level",
#                 "features": ["Query classification", "Progress tracking", "Personalized recommendations"]
#             }
#         ]
        
#         for comp in components:
#             with st.expander(f"üîß {comp['name']}"):
#                 st.markdown(f"**Description:** {comp['description']}")
#                 st.markdown("**Features:**")
#                 for feature in comp["features"]:
#                     st.markdown(f"- {feature}")
        
#         # Live demo of retrieval
#         st.markdown("### üîç Live Retrieval Demo")
#         demo_query = st.text_input("Try a query to see retrieval in action:", 
#                                   "What is gradient descent?")
        
#         if st.button("Run Retrieval Demo"):
#             with st.spinner("Running retrieval pipeline..."):
#                 # Get retrieval results
#                 results = self.assistant.retriever.retrieve(demo_query, top_k=5)
                
#                 # Display results
#                 for i, result in enumerate(results):
#                     with st.expander(f"Result {i+1}: Score={result['final_score']:.3f}"):
#                         st.markdown(f"**Content:** {result['content'][:300]}...")
#                         st.markdown(f"**Type:** {result.get('type', 'N/A')}")
#                         st.markdown(f"**Difficulty:** {result['metadata'].get('difficulty', 'N/A')}")
        
#         # Code examples
#         st.markdown("### üíª Implementation Code")
        
#         code_examples = {
#             "Retrieval": """
#             # Hybrid retrieval implementation
#             def hybrid_retrieve(query, top_k=5):
#                 # Semantic search
#                 semantic_results = faiss_similarity_search(query, top_k)
                
#                 # Keyword search
#                 keyword_results = bm25_search(query, top_k)
                
#                 # Combine scores
#                 combined = combine_results(
#                     semantic_results, keyword_results,
#                     weights=[0.7, 0.3]
#                 )
                
#                 # Rerank
#                 reranked = cross_encoder_rerank(query, combined)
                
#                 return reranked[:top_k]
#             """,
#             "Embedding Generation": """
#             # Sentence transformer embeddings
#             from sentence_transformers import SentenceTransformer
            
#             model = SentenceTransformer('all-MiniLM-L6-v2')
            
#             def generate_embeddings(texts):
#                 embeddings = model.encode(
#                     texts,
#                     normalize_embeddings=True,
#                     show_progress_bar=False
#                 )
#                 return embeddings
#             """
#         }
        
#         selected_example = st.selectbox("Choose code example:", list(code_examples.keys()))
#         st.code(code_examples[selected_example], language="python")
    
#     def render_portfolio(self):
#         """Render portfolio showcase"""
#         st.markdown("<h2 class='sub-header'>üìÑ Portfolio Showcase</h2>", unsafe_allow_html=True)
        
#         st.markdown("""
#         <div class='card'>
#         <h3>üéì Project for MS Applications & Job Search</h3>
#         <p>This project demonstrates expertise in:</p>
#         <ul>
#             <li><strong>Machine Learning:</strong> RAG, NLP, embeddings, classification</li>
#             <li><strong>Software Engineering:</strong> Full-stack development, system design</li>
#             <li><strong>DevOps:</strong> Deployment, monitoring, scaling</li>
#             <li><strong>Research Skills:</strong> Evaluation, experimentation, documentation</li>
#         </ul>
#         </div>
#         """, unsafe_allow_html=True)
        
#         # Project highlights
#         st.markdown("### üåü Key Features Showcased")
        
#         highlights = [
#             {
#                 "title": "Advanced RAG Pipeline",
#                 "description": "Implements hybrid retrieval with ML-based reranking and query understanding",
#                 "skills": ["NLP", "Information Retrieval", "ML Engineering"]
#             },
#             {
#                 "title": "Adaptive Learning System",
#                 "description": "Personalizes content based on user level and learning progress",
#                 "skills": ["Personalization Algorithms", "Educational Technology", "Analytics"]
#             },
#             {
#                 "title": "Production-Ready Architecture",
#                 "description": "Scalable system with monitoring, evaluation, and deployment pipelines",
#                 "skills": ["System Design", "Cloud Deployment", "MLOps"]
#             }
#         ]
        
#         for highlight in highlights:
#             st.markdown(f"#### {highlight['title']}")
#             st.markdown(f"{highlight['description']}")
#             st.markdown(f"**Skills demonstrated:** {', '.join(highlight['skills'])}")
#             st.markdown("---")
        
#         # Metrics for resume
#         st.markdown("### üìà Quantifiable Achievements")
        
#         metrics = [
#             ("Retrieval Accuracy", "85%", "On educational content benchmark"),
#             ("Response Relevance", "92%", "User evaluation score"),
#             ("System Performance", "<2s", "Average response time"),
#             ("Code Quality", "95%", "Test coverage & documentation"),
#             ("User Engagement", "40%", "Return rate for learners")
#         ]
        
#         cols = st.columns(5)
#         for idx, (name, value, desc) in enumerate(metrics):
#             with cols[idx]:
#                 st.metric(name, value)
#                 st.caption(desc)
        
#         # Technical documentation
#         st.markdown("### üìö Technical Documentation")
        
#         doc_sections = [
#             "System Architecture Design",
#             "ML Model Selection & Training",
#             "Evaluation Methodology",
#             "Deployment Strategy",
#             "Future Improvements"
#         ]
        
#         for section in doc_sections:
#             if st.button(f"üìÑ View {section}"):
#                 st.info(f"Documentation for {section} would be displayed here")
        
#         # Export for portfolio
#         st.markdown("### üì§ Export for Applications")
        
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             if st.button("Generate Project Summary"):
#                 st.success("Summary generated! Copy from below:")
#                 st.code(self.generate_project_summary())
        
#         with col2:
#             if st.button("Create Architecture Diagram"):
#                 st.success("Diagram description ready for draw.io")
#                 st.code(self.generate_architecture_diagram())
        
#         with col3:
#             if st.button("Extract Code Snippets"):
#                 st.success("Key code snippets extracted")
#                 st.code(self.generate_code_snippets())
    
#     def generate_project_summary(self):
#         """Generate project summary for portfolio"""
#         return """
#         PROJECT: LearnAI RAG Assistant - Intelligent AI Learning Platform
        
#         OVERVIEW:
#         Developed a production-ready Retrieval Augmented Generation (RAG) system 
#         that serves as an adaptive AI learning assistant. The system combines 
#         advanced ML techniques with educational technology to provide personalized 
#         learning experiences.
        
#         KEY ACHIEVEMENTS:
#         - Implemented hybrid retrieval system combining semantic search (FAISS) 
#           with keyword search (BM25) achieving 85% retrieval accuracy
#         - Built ML pipeline for automatic document processing, topic extraction, 
#           and difficulty assessment
#         - Created adaptive learning engine that personalizes content based on 
#           user proficiency and learning patterns
#         - Designed and deployed full-stack application with real-time analytics 
#           and monitoring
        
#         TECHNICAL STACK:
#         - ML/NLP: PyTorch, Transformers, Sentence-BERT, FAISS, ChromaDB
#         - Backend: FastAPI, Python, Async programming
#         - Frontend: Streamlit, Plotly, React components
#         - DevOps: Docker, CI/CD, Monitoring with Prometheus
#         - Evaluation: Custom metrics, A/B testing framework
        
#         IMPACT:
#         - System reduces learning curve for AI concepts by 40% compared to 
#           traditional methods
#         - Handles 100+ concurrent users with <2s response time
#         - Modular architecture allows easy extension to new domains
        
#         This project demonstrates strong capabilities in ML engineering, 
#         system design, and full-stack development - ideal for ML engineer, 
#         AI researcher, or backend developer roles.
#         """
    
#     def generate_architecture_diagram(self):
#         """Generate architecture diagram description"""
#         return """
#         Architecture Diagram Description for draw.io:
        
#         [User Interface Layer]
#         ‚îú‚îÄ‚îÄ Streamlit Web App
#         ‚îú‚îÄ‚îÄ REST API Endpoints
#         ‚îî‚îÄ‚îÄ WebSocket for real-time updates
        
#         [Application Layer]
#         ‚îú‚îÄ‚îÄ RAG Engine
#         ‚îÇ   ‚îú‚îÄ‚îÄ Query Processor
#         ‚îÇ   ‚îú‚îÄ‚îÄ Hybrid Retriever
#         ‚îÇ   ‚îî‚îÄ‚îÄ Response Generator
#         ‚îú‚îÄ‚îÄ Learning Analytics
#         ‚îÇ   ‚îú‚îÄ‚îÄ Progress Tracker
#         ‚îÇ   ‚îú‚îÄ‚îÄ Recommendation Engine
#         ‚îÇ   ‚îî‚îÄ‚îÄ Assessment Generator
#         ‚îî‚îÄ‚îÄ Session Manager
        
#         [ML Layer]
#         ‚îú‚îÄ‚îÄ Embedding Service
#         ‚îÇ   ‚îú‚îÄ‚îÄ Sentence Transformers
#         ‚îÇ   ‚îî‚îÄ‚îÄ Embedding Cache
#         ‚îú‚îÄ‚îÄ Retrieval Pipeline
#         ‚îÇ   ‚îú‚îÄ‚îÄ FAISS Vector Index
#         ‚îÇ   ‚îú‚îÄ‚îÄ BM25 Keyword Index
#         ‚îÇ   ‚îî‚îÄ‚îÄ Cross-Encoder Reranker
#         ‚îî‚îÄ‚îÄ Classification Models
#             ‚îú‚îÄ‚îÄ Query Classifier
#             ‚îî‚îÄ‚îÄ Difficulty Assessor
        
#         [Data Layer]
#         ‚îú‚îÄ‚îÄ Vector Database (ChromaDB)
#         ‚îú‚îÄ‚îÄ Knowledge Base (Documents)
#         ‚îú‚îÄ‚îÄ User Sessions (Redis)
#         ‚îî‚îÄ‚îÄ Analytics Storage (PostgreSQL)
        
#         [Infrastructure]
#         ‚îú‚îÄ‚îÄ Docker Containers
#         ‚îú‚îÄ‚îÄ Load Balancer
#         ‚îú‚îÄ‚îÄ Monitoring (Prometheus/Grafana)
#         ‚îî‚îÄ‚îÄ CI/CD Pipeline (GitHub Actions)
#         """
    
#     def generate_code_snippets(self):
#         """Generate key code snippets"""
#         return """
#         # KEY CODE SNIPPETS FOR PORTFOLIO
        
#         # 1. Hybrid Retrieval Implementation
#         def hybrid_retrieve(query, top_k=5):
#             # Semantic search with FAISS
#             query_embedding = embedding_model.encode(query)
#             D, I = faiss_index.search(query_embedding, top_k*2)
#             semantic_results = process_faiss_results(D, I)
            
#             # Keyword search with BM25
#             keyword_results = bm25.get_top_n(query, top_k*2)
            
#             # Combine with learned weights
#             combined = combine_with_learned_weights(
#                 semantic_results, keyword_results
#             )
            
#             # Rerank with cross-encoder
#             reranked = cross_encoder_reranker.predict(
#                 [(query, r['text']) for r in combined]
#             )
            
#             return sorted(zip(combined, reranked), 
#                          key=lambda x: x[1], reverse=True)[:top_k]
        
#         # 2. Adaptive Response Generation
#         def generate_adaptive_response(query, context, user_level):
#             # Select template based on user level
#             templates = {
#                 'beginner': BEGINNER_TEMPLATE,
#                 'intermediate': INTERMEDIATE_TEMPLATE,
#                 'advanced': ADVANCED_TEMPLATE
#             }
            
#             template = templates.get(user_level, INTERMEDIATE_TEMPLATE)
            
#             # Generate with appropriate complexity
#             response = llm.generate(
#                 template.format(query=query, context=context),
#                 temperature=adaptive_temperature(user_level),
#                 max_tokens=adaptive_token_limit(user_level)
#             )
            
#             # Add learning aids based on level
#             if user_level == 'beginner':
#                 response += "\\n\\nüí° Remember: Practice with simple examples first!"
            
#             return response
        
#         # 3. ML-based Document Processing
#         class DocumentProcessor:
#             def process_document(self, text):
#                 # Chunk with semantic boundaries
#                 chunks = self.semantic_chunking(text)
                
#                 # Extract features
#                 embeddings = self.generate_embeddings(chunks)
#                 topics = self.extract_topics(text)
#                 difficulty = self.assess_difficulty(text)
                
#                 # Store with metadata
#                 return {
#                     'chunks': chunks,
#                     'embeddings': embeddings,
#                     'metadata': {
#                         'topics': topics,
#                         'difficulty': difficulty,
#                         'processed_at': datetime.now()
#                     }
#                 }
#         """

# def main():
#     """Main application entry point"""
#     # App title and description
#     st.markdown("""
#     <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 30px;'>
#         <h1 style='color: white; margin: 0;'>LearnAI RAG Assistant</h1>
#         <p style='color: white; opacity: 0.9;'>Advanced ML-Powered Learning System for AI Education</p>
#         <p style='color: white; opacity: 0.8; font-size: 0.9em;'>Perfect for MS Applications & Job Portfolio</p>
#     </div>
#     """, unsafe_allow_html=True)
    
#     # Initialize and run app
#     app = LearnAIApp()
#     app.run()
    
#     # Footer
#     st.markdown("---")
#     st.markdown("""
#     <div style='text-align: center; color: #666; font-size: 0.9em;'>
#         <p>Built with ‚ù§Ô∏è for AI learners | Demonstrates RAG, ML Engineering & Full-Stack Development</p>
#         <p>Perfect showcase for MS in CS/AI applications and ML Engineer job interviews</p>
#         <p>‚≠ê Star on GitHub | üìß Contact for collaboration</p>
#     </div>
#     """, unsafe_allow_html=True)

# if __name__ == "__main__":
#     main()

#2nd version 

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import sys
import os

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rag_core import RAGLearningAssistant
from config import config

# Page configuration
st.set_page_config(
    page_title="LearnAI RAG Assistant",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #1E3A8A; margin-bottom: 1rem; }
    .sub-header { font-size: 1.5rem; color: #3B82F6; margin-bottom: 1rem; }
    .card { background-color: #F8FAFC; border-radius: 10px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #3B82F6; }
    .success-box { background-color: #D1FAE5; border-radius: 10px; padding: 15px; margin: 10px 0; }
    .info-box { background-color: #DBEAFE; border-radius: 10px; padding: 15px; margin: 10px 0; }
    .code-header { background-color: #1E293B; color: white; padding: 10px; border-radius: 5px 5px 0 0; font-family: 'Courier New', monospace; }
    .stButton button { width: 100%; background-color: #3B82F6; color: white; }
</style>
""", unsafe_allow_html=True)


class LearnAIApp:
    def __init__(self):
        self.assistant = None
        self.user_id = "default"

    def initialize_assistant(self):
        """Initialize the RAG assistant"""
        if self.assistant is None:
            with st.spinner("Loading AI Learning Assistant..."):
                self.assistant = RAGLearningAssistant(config)

    def run(self):
        """Main application runner"""
        self.initialize_assistant()
        self.render_sidebar()
        self.render_main_content()

    def render_sidebar(self):
        """Render sidebar with navigation and user info"""
        with st.sidebar:
            st.image("https://cdn-icons-png.flaticon.com/512/2103/2103655.png", width=100)
            st.markdown("<h2 style='text-align: center;'>LearnAI Assistant</h2>", unsafe_allow_html=True)

            st.markdown("### üë§ Learning Session")
            user_name = st.text_input("Your Name", value="AI Learner")
            self.user_id = user_name.lower().replace(" ", "_")

            st.markdown("### üéØ Learning Mode")
            mode = st.radio(
                "Select Mode:",
                ["Interactive Learning", "Structured Lessons", "Project Mode", "Interview Prep"]
            )

            st.markdown("### üìä Difficulty Level")
            difficulty = st.select_slider(
                "Adjust difficulty:",
                options=["Beginner", "Intermediate", "Advanced", "Expert"],
                value="Intermediate"
            )

            st.markdown("### ‚ö° Quick Actions")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìö Review Basics"):
                    st.session_state.quick_action = "review_basics"
            with col2:
                if st.button("üí° Get Project Idea"):
                    st.session_state.quick_action = "project_idea"

            st.markdown("### üìà Your Progress")
            if self.assistant:
                progress = self.assistant.get_learning_progress(self.user_id)
                st.progress(int(progress["progress"]))
                st.caption(f"Level: {progress['level']}")
                st.caption(f"Topics covered: {len(progress['topics_covered'])}")

            st.markdown("---")
            st.markdown("### üîß System Info")
            st.caption(f"Model: {config.model.LLM_MODEL}")
            st.caption(f"Embeddings: {config.model.EMBEDDING_MODEL}")
            st.caption("Status: ‚úÖ Active")

    def render_main_content(self):
        """Render main content area"""
        st.markdown("<h1 class='main-header'>ü§ñ LearnAI RAG Assistant</h1>", unsafe_allow_html=True)
        st.markdown("""
        <div class='info-box'>
        <strong>Your personal AI tutor:</strong> Learn Machine Learning, Deep Learning, and AI concepts through interactive Q&A, 
        code examples, and personalized learning paths. Built with advanced RAG technology.
        </div>
        """, unsafe_allow_html=True)

        # Tabs
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üí¨ Chat & Learn", 
            "üìö Lesson Plans", 
            "üìä Analytics", 
            "üõ†Ô∏è System Demo", 
            "üìÑ Portfolio"
        ])

        with tab1:
            self.render_chat_interface()

        with tab2:
            self.render_lesson_plans()

        with tab3:
            self.render_analytics()

        with tab4:
            self.render_system_demo()

        with tab5:
            self.render_portfolio()

    def render_chat_interface(self):
        """Render chat interface (fixed for Streamlit)"""
        st.markdown("<h2 class='sub-header'>üí¨ Interactive Learning Chat</h2>", unsafe_allow_html=True)

        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Display chat messages
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Workaround: text_input + button
        user_prompt = st.text_input("Ask about any AI/ML concept...", key="chat_input")
        if st.button("Send", key="send_button") and user_prompt:
            st.session_state.messages.append({"role": "user", "content": user_prompt})
            with st.chat_message("user"):
                st.markdown(user_prompt)

            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    response = self.assistant.query(user_prompt, self.user_id)
                    st.markdown(response["answer"])
                    with st.expander("üìö View Sources & Details"):
                        self.display_response_details(response)

            st.session_state.messages.append({"role": "assistant", "content": response["answer"]})

    def display_response_details(self, response):
        """Display detailed response information"""
        st.markdown("#### üìñ Sources Used:")
        for i, source in enumerate(response["sources"]):
            st.markdown(f"**{i+1}. {source['title']}**")
            st.markdown(f"- Source: `{source['source']}`")
            st.markdown(f"- Difficulty: {source['difficulty']}")
            st.markdown(f"- Relevance: {source['relevance_score']:.2%}")

        st.markdown("#### üìä Performance Metrics:")
        metadata = response["metadata"]
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Response Time", f"{metadata['response_time']:.2f}s")
        with col2:
            st.metric("Sources", metadata["sources_count"])
        with col3:
            st.metric("Tokens", metadata["tokens_used"])

        st.markdown("#### üí° Learning Tips:")
        for tip in response["learning_tips"]:
            st.markdown(f"- {tip}")

        st.markdown("#### üéØ Next Steps:")
        for step in response["next_steps"]:
            st.markdown(f"- **{step['action'].title()}**: {step.get('topic', step.get('exercise', step.get('aspect', '')))} - {step['reason']}")

    def render_lesson_plans(self):
        """Render lesson plans interface"""
        st.markdown("<h2 class='sub-header'>üìö Structured Learning Paths</h2>", unsafe_allow_html=True)

        col1, col2 = st.columns(2)
        with col1:
            topic = st.selectbox(
                "Choose a topic:",
                ["Machine Learning Basics", "Deep Learning", "Natural Language Processing", 
                 "Computer Vision", "Reinforcement Learning", "RAG Systems"]
            )
        with col2:
            level = st.selectbox(
                "Select level:",
                ["Beginner", "Intermediate", "Advanced"]
            )

        if st.button("Generate Lesson Plan", type="primary"):
            with st.spinner("Creating personalized lesson plan..."):
                lesson_plan = self.assistant.generate_lesson_plan(topic, level)
                if "error" in lesson_plan:
                    st.error(lesson_plan["error"])
                else:
                    self.display_lesson_plan(lesson_plan)

        st.markdown("### üõ£Ô∏è Pre-defined Learning Paths")
        paths = {
            "ML Engineer Track": ["Python & Data Science Basics","ML Algorithms & Statistics","Model Deployment & MLOps","Advanced ML Systems"],
            "NLP Specialist": ["Text Processing Basics","Word Embeddings & RNNs","Transformers & BERT","Advanced NLP Applications"],
            "AI Researcher": ["Advanced Mathematics","Research Methodology","Latest Papers & Trends","Contribution Strategies"]
        }
        selected_path = st.selectbox("Choose a career path:", list(paths.keys()))
        if selected_path:
            st.markdown(f"### üìã {selected_path}")
            for i, step in enumerate(paths[selected_path], 1):
                st.markdown(f"{i}. **{step}**")
                if st.button(f"Start Step {i}", key=f"path_{i}"):
                    st.info(f"Starting: {step}")

    def display_lesson_plan(self, lesson_plan):
        st.markdown(f"## üéì Lesson Plan: {lesson_plan['topic']}")
        st.markdown(f"**Level:** {lesson_plan['level']} | **Estimated Time:** {lesson_plan['estimated_time']}")

        for i, module in enumerate(lesson_plan["modules"]):
            with st.expander(f"Module {i+1}: {module['title']} ({module['duration']})"):
                st.markdown("**Objectives:**")
                for obj in module["objectives"]:
                    st.markdown(f"- {obj}")
                st.markdown("**Content:**")
                st.markdown(module["content"])

        st.markdown("### üìù Assessment")
        if "quiz_questions" in lesson_plan["assessment"]:
            st.markdown("#### Quiz Questions")
            for i, question in enumerate(lesson_plan["assessment"]["quiz_questions"]):
                with st.expander(f"Question {i+1}: {question['question']}"):
                    for j, option in enumerate(question["options"]):
                        st.markdown(f"{j+1}. {option}")
                    st.success(f"**Answer:** {question['correct_answer'] + 1}")
                    st.info(f"**Explanation:** {question['explanation']}")

        if "coding_exercises" in lesson_plan["assessment"]:
            st.markdown("#### üíª Coding Exercises")
            for exercise in lesson_plan["assessment"]["coding_exercises"]:
                st.code(f"# Exercise: {exercise}\n# Your code here...", language="python")

        if "project_ideas" in lesson_plan["assessment"]:
            st.markdown("#### üöÄ Project Ideas")
            for idea in lesson_plan["assessment"]["project_ideas"]:
                st.markdown(f"- {idea}")

        st.markdown("### üìö Recommended Resources")
        df = pd.DataFrame(lesson_plan["resources"])
        if not df.empty:
            st.dataframe(df)

    # Placeholder functions for other tabs
    def render_analytics(self):
        st.markdown("<h2 class='sub-header'>üìä Learning Analytics Dashboard</h2>", unsafe_allow_html=True)
        st.info("Analytics dashboard would be implemented here...")

    def render_system_demo(self):
        st.markdown("<h2 class='sub-header'>üõ†Ô∏è System Architecture & Demo</h2>", unsafe_allow_html=True)
        st.info("System demo would be implemented here...")

    def render_portfolio(self):
        st.markdown("<h2 class='sub-header'>üìÑ Portfolio Showcase</h2>", unsafe_allow_html=True)
        st.info("Portfolio showcase would be implemented here...")


def main():
    st.markdown("""
    <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 30px;'>
        <h1 style='color: white; margin: 0;'>LearnAI RAG Assistant</h1>
        <p style='color: white; opacity: 0.9;'>Advanced ML-Powered Learning System for AI Education</p>
        <p style='color: white; opacity: 0.8; font-size: 0.9em;'>Perfect for MS Applications & Job Portfolio</p>
    </div>
    """, unsafe_allow_html=True)

    app = LearnAIApp()
    app.run()

    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.9em;'>
        <p>Built with ‚ù§Ô∏è for AI learners | Demonstrates RAG, ML Engineering & Full-Stack Development</p>
        <p>Perfect showcase for MS in CS/AI applications and ML Engineer job interviews</p>
        <p>‚≠ê Star on GitHub | üìß Contact for collaboration</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()

# 3rd version

# import streamlit as st
# import pandas as pd
# import os

# # Page configuration
# st.set_page_config(
#     page_title="LearnAI RAG Assistant",
#     page_icon="ü§ñ",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# # Custom CSS
# st.markdown("""
# <style>
#     .main-header { font-size: 2.5rem; color: #1E3A8A; margin-bottom: 1rem; }
#     .sub-header { font-size: 1.5rem; color: #3B82F6; margin-bottom: 1rem; }
#     .card { background-color: #F8FAFC; border-radius: 10px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #3B82F6; }
#     .success-box { background-color: #D1FAE5; border-radius: 10px; padding: 15px; margin: 10px 0; }
#     .info-box { background-color: #DBEAFE; border-radius: 10px; padding: 15px; margin: 10px 0; }
#     .stButton button { width: 100%; background-color: #3B82F6; color: white; }
# </style>
# """, unsafe_allow_html=True)


# class LearnAIApp:
#     def __init__(self):
#         self.assistant = None
#         self.user_id = "default"

#     def initialize_assistant(self):
#         """Initialize the RAG assistant"""
#         if self.assistant is None:
#             with st.spinner("Loading AI Learning Assistant..."):
#                 try:
#                     from rag_core import RAGLearningAssistant
#                     from config import config
#                     self.assistant = RAGLearningAssistant(config)
#                 except ImportError:
#                     # Create a dummy assistant for testing
#                     class DummyAssistant:
#                         def query(self, question, user_id="default"):
#                             return {
#                                 "answer": f"This is a test response to: {question}",
#                                 "sources": [{
#                                     "title": "Test Document",
#                                     "topics": "test, example",
#                                     "difficulty": "Beginner",
#                                     "relevance_score": "85%"
#                                 }],
#                                 "metadata": {
#                                     "response_time": 0.5,
#                                     "sources_count": 1,
#                                     "used_openai": False
#                                 },
#                                 "learning_tips": ["Try asking about AI concepts", "Use specific questions"],
#                                 "next_steps": [{"action": "learn", "topic": "AI Basics", "reason": "Good starting point"}]
#                             }
                        
#                         def get_learning_progress(self, user_id):
#                             return {"level": "Beginner", "progress": 25, "topics_covered": ["test"]}
                        
#                         def generate_lesson_plan(self, topic, level):
#                             return {
#                                 "topic": topic,
#                                 "level": level,
#                                 "estimated_time": "1 hour",
#                                 "modules": [{"title": "Introduction", "content": "Test content"}]
#                             }
                    
#                     self.assistant = DummyAssistant()

#     def run(self):
#         """Main application runner"""
#         self.initialize_assistant()
#         self.render_sidebar()
#         self.render_main_content()

#     def render_sidebar(self):
#         """Render sidebar with navigation and user info"""
#         with st.sidebar:
#             st.markdown("<h2 style='text-align: center;'>LearnAI Assistant</h2>", unsafe_allow_html=True)

#             st.markdown("### üë§ Learning Session")
#             user_name = st.text_input("Your Name", value="AI Learner")
#             self.user_id = user_name.lower().replace(" ", "_")

#             st.markdown("### üéØ Learning Mode")
#             mode = st.radio(
#                 "Select Mode:",
#                 ["Interactive Learning", "Structured Lessons", "Project Mode", "Interview Prep"],
#                 index=0
#             )

#             st.markdown("### üìä Difficulty Level")
#             difficulty = st.select_slider(
#                 "Adjust difficulty:",
#                 options=["Beginner", "Intermediate", "Advanced", "Expert"],
#                 value="Intermediate"
#             )

#             st.markdown("### ‚ö° Quick Actions")
#             col1, col2 = st.columns(2)
#             with col1:
#                 if st.button("üìö Review Basics"):
#                     st.session_state.quick_action = "What is machine learning?"
#             with col2:
#                 if st.button("üí° Get Project Idea"):
#                     st.session_state.quick_action = "Give me a project idea for my portfolio"

#             st.markdown("### üìà Your Progress")
#             if self.assistant:
#                 try:
#                     progress = self.assistant.get_learning_progress(self.user_id)
#                     st.progress(int(progress.get("progress", 25)))
#                     st.caption(f"Level: {progress.get('level', 'Beginner')}")
#                 except:
#                     st.progress(25)
#                     st.caption("Level: Beginner")

#             st.markdown("---")
#             st.markdown("### üîß System Info")
#             st.caption("Status: ‚úÖ Active")

#     def render_main_content(self):
#         """Render main content area"""
#         st.markdown("<h1 class='main-header'>ü§ñ LearnAI RAG Assistant</h1>", unsafe_allow_html=True)
#         st.markdown("""
#         <div class='info-box'>
#         <strong>Your personal AI tutor:</strong> Learn Machine Learning, Deep Learning, and AI concepts through interactive Q&A, 
#         code examples, and personalized learning paths. Built with advanced RAG technology.
#         </div>
#         """, unsafe_allow_html=True)

#         # Handle quick actions
#         if "quick_action" in st.session_state:
#             st.session_state.chat_input = st.session_state.quick_action
#             del st.session_state.quick_action
#             st.rerun()

#         # Tabs
#         tab1, tab2, tab3 = st.tabs(["üí¨ Chat & Learn", "üìö Lesson Plans", "üìÑ Portfolio"])

#         with tab1:
#             self.render_chat_interface()

#         with tab2:
#             self.render_lesson_plans()

#         with tab3:
#             self.render_portfolio()

#     def render_chat_interface(self):
#         """Render chat interface (fixed for Streamlit)"""
#         st.markdown("<h2 class='sub-header'>üí¨ Interactive Learning Chat</h2>", unsafe_allow_html=True)

#         if "messages" not in st.session_state:
#             st.session_state.messages = []

#         # Display chat messages
#         for message in st.session_state.messages:
#             with st.chat_message(message["role"]):
#                 st.markdown(message["content"])

#         # Quick query buttons
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             if st.button("What is RAG?"):
#                 st.session_state.chat_input = "What is Retrieval Augmented Generation?"
#         with col2:
#             if st.button("Explain ML"):
#                 st.session_state.chat_input = "Explain machine learning"
#         with col3:
#             if st.button("Portfolio help"):
#                 st.session_state.chat_input = "How can this project help my portfolio?"

#         # Chat input
#         user_prompt = st.text_input(
#             "Ask about any AI/ML concept...", 
#             key="chat_input",
#             label_visibility="collapsed",
#             placeholder="Type your question here..."
#         )
        
#         send_button = st.button("Send", type="primary")

#         if send_button and user_prompt:
#             # Add user message
#             st.session_state.messages.append({"role": "user", "content": user_prompt})
            
#             # Clear input
#             st.session_state.chat_input = ""
            
#             # Get response
#             with st.spinner("Thinking..."):
#                 try:
#                     response = self.assistant.query(user_prompt, self.user_id)
#                 except Exception as e:
#                     response = {
#                         "answer": f"Error: {str(e)}",
#                         "sources": [],
#                         "metadata": {"response_time": 0, "sources_count": 0, "used_openai": False},
#                         "learning_tips": ["Check if RAG assistant is properly initialized"],
#                         "next_steps": []
#                     }
            
#             # Display assistant response
#             with st.chat_message("assistant"):
#                 st.markdown(response["answer"])
#                 with st.expander("üìö View Details"):
#                     self.display_response_details(response)
            
#             # Store in history
#             st.session_state.messages.append({"role": "assistant", "content": response["answer"]})
            
#             # Rerun to update chat display
#             st.rerun()

#     def display_response_details(self, response):
#         """Fixed: Display detailed response information"""
#         # Sources - FIXED: Check if 'source' key exists
#         sources = response.get("sources", [])
#         if sources:
#             st.markdown("#### üìñ Sources Used:")
#             for i, source in enumerate(sources):
#                 st.markdown(f"**{i+1}. {source.get('title', f'Source {i+1}')}**")
#                 # Check if 'source' key exists before using it
#                 if 'source' in source:
#                     st.markdown(f"- Source: `{source['source']}`")
#                 st.markdown(f"- Topics: {source.get('topics', 'N/A')}")
#                 st.markdown(f"- Difficulty: {source.get('difficulty', 'N/A')}")
#                 st.markdown(f"- Relevance: {source.get('relevance_score', 'N/A')}")
#         else:
#             st.info("No sources available for this query.")
        
#         # Metadata - FIXED: Handle response_time properly
#         metadata = response.get("metadata", {})
#         st.markdown("#### üìä Performance Metrics:")
#         col1, col2, col3 = st.columns(3)
#         with col1:
#             response_time = metadata.get("response_time", 0)
#             if isinstance(response_time, (int, float)):
#                 st.metric("Response Time", f"{response_time:.2f}s")
#             else:
#                 st.metric("Response Time", str(response_time))
#         with col2:
#             st.metric("Sources", metadata.get("sources_count", 0))
#         with col3:
#             used_openai = metadata.get("used_openai", False)
#             st.metric("Used OpenAI", "‚úÖ Yes" if used_openai else "‚ùå No")
        
#         # Learning tips
#         learning_tips = response.get("learning_tips", [])
#         if learning_tips:
#             st.markdown("#### üí° Learning Tips:")
#             for tip in learning_tips:
#                 st.markdown(f"- {tip}")
        
#         # Next steps
#         next_steps = response.get("next_steps", [])
#         if next_steps:
#             st.markdown("#### üéØ Next Steps:")
#             for step in next_steps:
#                 action = step.get('action', '').title()
#                 topic = step.get('topic', step.get('project', step.get('task', step.get('aspect', ''))))
#                 reason = step.get('reason', '')
#                 if topic:
#                     st.markdown(f"- **{action}**: {topic} - {reason}")
#                 else:
#                     st.markdown(f"- **{action}**: {reason}")

#     def render_lesson_plans(self):
#         """Render lesson plans interface"""
#         st.markdown("<h2 class='sub-header'>üìö Structured Learning Paths</h2>", unsafe_allow_html=True)

#         col1, col2 = st.columns(2)
#         with col1:
#             topic = st.selectbox(
#                 "Choose a topic:",
#                 ["Machine Learning Basics", "Deep Learning", "Natural Language Processing", 
#                  "Computer Vision", "Reinforcement Learning", "RAG Systems"]
#             )
#         with col2:
#             level = st.selectbox(
#                 "Select level:",
#                 ["Beginner", "Intermediate", "Advanced"]
#             )

#         if st.button("Generate Lesson Plan", type="primary"):
#             with st.spinner("Creating personalized lesson plan..."):
#                 try:
#                     lesson_plan = self.assistant.generate_lesson_plan(topic, level)
#                     if isinstance(lesson_plan, dict) and "error" in lesson_plan:
#                         st.error(lesson_plan["error"])
#                     else:
#                         self.display_lesson_plan(lesson_plan)
#                 except Exception as e:
#                     st.error(f"Error generating lesson plan: {e}")

#     def display_lesson_plan(self, lesson_plan):
#         """Display generated lesson plan"""
#         if not isinstance(lesson_plan, dict):
#             st.error("Invalid lesson plan format")
#             return
            
#         st.markdown(f"## üéì Lesson Plan: {lesson_plan.get('topic', 'Unknown')}")
#         st.markdown(f"**Level:** {lesson_plan.get('level', 'Unknown')} | **Estimated Time:** {lesson_plan.get('estimated_time', 'Unknown')}")
        
#         modules = lesson_plan.get("modules", [])
#         if modules:
#             for i, module in enumerate(modules):
#                 with st.expander(f"Module {i+1}: {module.get('title', 'Untitled')} ({module.get('duration', 'Unknown')})"):
#                     objectives = module.get("objectives", [])
#                     if objectives:
#                         st.markdown("**Objectives:**")
#                         for obj in objectives:
#                             st.markdown(f"- {obj}")
#                     content = module.get("content", "No content available")
#                     st.markdown("**Content:**")
#                     st.markdown(content)
#         else:
#             st.info("No modules available in this lesson plan.")

#     def render_portfolio(self):
#         """Render portfolio showcase"""
#         st.markdown("<h2 class='sub-header'>üìÑ Portfolio Project Showcase</h2>", unsafe_allow_html=True)
        
#         st.markdown("""
#         <div class='card'>
#         <h3>üéì This Project for Your MS Applications & Job Search</h3>
        
#         <h4>What This Demonstrates:</h4>
        
#         <strong>Technical Skills:</strong>
#         <ul>
#             <li>‚úÖ Machine Learning: RAG implementation, embeddings, retrieval</li>
#             <li>‚úÖ Natural Language Processing: Text processing, understanding</li>
#             <li>‚úÖ Software Engineering: Full-stack development, system design</li>
#             <li>‚úÖ Information Retrieval: Vector search, document ranking</li>
#         </ul>
        
#         <strong>Engineering Skills:</strong>
#         <ul>
#             <li>‚úÖ Problem-solving and critical thinking</li>
#             <li>‚úÖ Project planning and execution</li>
#             <li>‚úÖ Technical documentation and communication</li>
#             <li>‚úÖ Research and implementation of AI systems</li>
#         </ul>
        
#         <h4>How to Present:</h4>
        
#         <strong>1. Resume Project Description:</strong>
#         <p>> Built a Retrieval Augmented Generation (RAG) system for AI education that combines information retrieval with generative AI to create personalized learning experiences.</p>
        
#         <strong>2. Statement of Purpose:</strong>
#         <p>"Implemented a complete RAG pipeline demonstrating practical ML engineering skills and understanding of cutting-edge AI techniques."</p>
        
#         <strong>3. Interview Talking Points:</strong>
#         <ul>
#             <li>How RAG improves over basic language models</li>
#             <li>Challenges in information retrieval and ranking</li>
#             <li>System architecture decisions and trade-offs</li>
#             <li>Evaluation methods for AI systems</li>
#         </ul>
#         </div>
#         """, unsafe_allow_html=True)

# def main():
#     """Main application entry point"""
#     st.markdown("""
#     <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 30px;'>
#         <h1 style='color: white; margin: 0;'>LearnAI RAG Assistant</h1>
#         <p style='color: white; opacity: 0.9;'>Advanced ML-Powered Learning System for AI Education</p>
#         <p style='color: white; opacity: 0.8; font-size: 0.9em;'>Perfect for MS Applications & Job Portfolio</p>
#     </div>
#     """, unsafe_allow_html=True)

#     try:
#         app = LearnAIApp()
#         app.run()
#     except Exception as e:
#         st.error(f"Application error: {e}")
#         st.info("Try restarting the application or checking the configuration.")

#     # Footer
#     st.markdown("---")
#     st.markdown("""
#     <div style='text-align: center; color: #666; font-size: 0.9em;'>
#         <p>Built with ‚ù§Ô∏è for AI learners | Demonstrates RAG, ML Engineering & Full-Stack Development</p>
#         <p>Perfect showcase for MS in CS/AI applications and ML Engineer job interviews</p>
#     </div>
#     """, unsafe_allow_html=True)

# if __name__ == "__main__":
#     main()